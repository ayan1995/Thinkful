{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opinion Mining: Information Extraction for Product Development\n",
    "#### Ayan Karim\n",
    "\n",
    "## Introduction \n",
    "\n",
    "We already know about the immense amount of data that companies collect every day. But beyond the company's own databases exist an entire corpus of information online that they don't have direct access to. Any company that sells a product in mass production generates a huge amount of public opinion on the product and tons of reviews, articles, reactions and overall sentiments are posted online, especially soon after release. As of 2017, 223 million iPhones were sold in the US (Apple) which is huge considering the population was 325 million (this information was from 2017)[1]! This type of reach definitely results in tons of opinion online about how consumers feel about the product. \n",
    "\n",
    "So now when companies see this wealth of information that isn't a part of their own analytics, they want to access it to learn about how they can make their products better, or how they're products are performing. The problem is, how do companies access this data from the public media and turn it into something useful? How do we extract all that diverse information from the web and analyze it? This is where Opinion Mining comes in.\n",
    "\n",
    "\n",
    "### What is Opinion Mining?\n",
    "\n",
    "\"Opinion Mining\" is one of the most useful applications of Data Science in which a pipeline is designed to process and interpret public opinion about various products. The source of this data usually comes from public sources like reviews, article and social media so that the company can gain a diverse understanding of how people feel about their products.\n",
    "\n",
    "My endeavor with this project is to create a pipeline that solves this problem. So, I developed a Data Science product that collects information from the web, that processes and models the text data, and finally gives an end-user a summary of sentiments concerning their product which they can then use for product development. To take it a step further, this pipeline also applies the same process to another product that's in competition. For the sake of my demo, my target product is an iPhone X, and I compare it to Samsung's Galaxy S9.\n",
    "\n",
    "\n",
    "### What is Aspect-Based Sentiment Analysis?\n",
    "\n",
    "The type of analysis done in this product is called Aspect-Based Sentiment Analysis. This basically means our model will extract sentiments of a product within context. So, the model will parse the text, sentence by sentence, and extract the sentiment (positive or negative) as well as the aspect that the sentiment is about. For example, in the sentence, \"The battery is so unreliable.\", our dependency parser will extract a negative sentiment from \"unreliable\" and extract the fact that it's talking about the \"battery\".\n",
    "\n",
    "\n",
    "### Let’s Pretend We’re Apple!\n",
    "\n",
    "We want to understand public opinion about the iPhone X and gain actionable insights to make our next product better. The questions that guide our investigation are:\n",
    "\n",
    "#### What does Public Opinion tell us about the iPhone X?\n",
    "#### What are some negative aspects of the iPhone X that people dislike about our product?\n",
    "#### How does our product compare with that of a competing smartphone like the Samsung Galaxy S9?\n",
    "\n",
    "\n",
    "### Technology Pipeline:\n",
    "\n",
    "1. Scrapy to scrape information from the web\n",
    "2. NLTK, Spacy and Gensim's simple_process to process texts\n",
    "3. Gensim's Latent Dirichlet Allocation to extract and assign topics\n",
    "4. pyLDAvis for visualization\n",
    "5. Scikit Learn, Multi-Label Naive Bayes and Support Vector Machines to train text data on Topics\n",
    "6. Scikit Multilearn, PowerLabelset to train on multiple labels\n",
    "7. Opinion Lexicon by Minqinq Hu and Bing Liu\n",
    "8. Spacy Dependency Parser, Countvectorizer and TF-IDF vectorizer for Aspect-Based Semantic Analysis\n",
    "9. Word2Vec pre-trained on Google's News dataset for assigning aspects and sentiments to topics\n",
    "10. Matplotlib and Seaborn for data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies and modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import string\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "from io import StringIO\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "\n",
    "\n",
    "import nltk\n",
    "import glob\n",
    "import errno\n",
    "import os\n",
    "import json\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim import models, corpora, similarities\n",
    "from gensim.models import CoherenceModel, TfidfModel\n",
    "from itertools import chain\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the Data\n",
    "\n",
    "As we've mentioned before, the goal of this project is to make use of data found from public media. So, the first thing I've done is scrape text data from articles and reviews from digitaltrends.com, gizmodo.com and techradar.com. I scraped anything I could find on the following phones:\n",
    "\n",
    "1. iPhone X\n",
    "2. Galaxy S9\n",
    "3. Pixel 3\n",
    "4. Huawei Mate 20 Pro\n",
    "5. OnePlus 6T\n",
    "6. Huawei P2 Pro\n",
    "7. LG V4 Thinq\n",
    "8. Sony Xperia XZ3\n",
    "9. Essential Phone\n",
    "10. Razer Phone 2\n",
    "11. HTC U12+\n",
    "12. Moto G6 plus\n",
    "\n",
    "You'll notice that I've listed far more phones than just the iPhone X and Galaxy S9. We need as much data as possible for the sake of topic modeling. If we have more text information we have about phones, we can extract more sparse topics.\n",
    "\n",
    "### Scraping the Data.\n",
    "\n",
    "To scrape the data, I used Python's scraping and web crawling framework called Scrapy. I built 23 custom crawlers to crawl, paginate and scraped content from links in search queries and produced 285 texts of data, that vary in length, in JSON format. This text data included any information about phones that comes to mind such reviews, opinion pieces, comparisons, price, etc. The initial data set consisted title, author and the text of the articles that were scraped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame to hold json data\n",
    "json_data = pd.DataFrame(columns = ['author', 'text', 'title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path to text files that contain the novels\n",
    "path = '/Users/ayankarim/Documents/Thinkful/Bootcamp/Final Capstone Opinion Mining/Opinion Mining/Notebooks/01 Topic Modelling/files/*.json'\n",
    "files = glob.glob(path)\n",
    "\n",
    "# Populate a list with the json objects\n",
    "all_jsons = []\n",
    "\n",
    "for filenames in files:\n",
    "    with open(filenames, 'r') as f:\n",
    "        file = json.load(f)\n",
    "        all_jsons.append(file)\n",
    "\n",
    "# Create a DataFrame of all json objects\n",
    "for dicts in all_jsons:\n",
    "    df = pd.DataFrame(dicts)\n",
    "    json_data = json_data.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[\\n\\t\\t\\t\\t\\t\\tJulian Chokkattu\\t\\t\\t\\t\\t]</td>\n",
       "      <td>[&lt;p&gt;Google’s &lt;a href=\"https://store.google.com...</td>\n",
       "      <td>\\n\\t\\tGoogle will announce hardware on October...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[\\n\\t\\t\\t\\t\\t\\tChristian de Looper\\t\\t\\t\\t\\t]</td>\n",
       "      <td>[&lt;p&gt;Google finally unveiled the new &lt;a href=\"h...</td>\n",
       "      <td>\\n\\t\\tHere’s how to buy the new Google Pixel 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[\\n\\t\\t\\t\\t\\t\\tSimon Hill\\t\\t\\t\\t\\t]</td>\n",
       "      <td>[&lt;p&gt;If you plan to buy one of Google’s &lt;a href...</td>\n",
       "      <td>\\n\\t\\tThe best Pixel 3 cases and covers\\t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[\\n\\t\\t\\t\\t\\t\\tSimon Hill\\t\\t\\t\\t\\t]</td>\n",
       "      <td>[&lt;p&gt;As the developer of Android, Google turns ...</td>\n",
       "      <td>\\n\\t\\tGoogle Pixel 3 vs. Pixel 2 vs. Pixel: Pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[\\n\\t\\t\\t\\t\\t\\tSimon Hill\\t\\t\\t\\t\\t]</td>\n",
       "      <td>[&lt;p&gt;There are plenty of contenders in the &lt;a h...</td>\n",
       "      <td>\\n\\t\\tGoogle Pixel 3 vs. Samsung Galaxy S9: Wh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          author  \\\n",
       "0     [\\n\\t\\t\\t\\t\\t\\tJulian Chokkattu\\t\\t\\t\\t\\t]   \n",
       "1  [\\n\\t\\t\\t\\t\\t\\tChristian de Looper\\t\\t\\t\\t\\t]   \n",
       "2           [\\n\\t\\t\\t\\t\\t\\tSimon Hill\\t\\t\\t\\t\\t]   \n",
       "3           [\\n\\t\\t\\t\\t\\t\\tSimon Hill\\t\\t\\t\\t\\t]   \n",
       "4           [\\n\\t\\t\\t\\t\\t\\tSimon Hill\\t\\t\\t\\t\\t]   \n",
       "\n",
       "                                                text  \\\n",
       "0  [<p>Google’s <a href=\"https://store.google.com...   \n",
       "1  [<p>Google finally unveiled the new <a href=\"h...   \n",
       "2  [<p>If you plan to buy one of Google’s <a href...   \n",
       "3  [<p>As the developer of Android, Google turns ...   \n",
       "4  [<p>There are plenty of contenders in the <a h...   \n",
       "\n",
       "                                               title  \n",
       "0  \\n\\t\\tGoogle will announce hardware on October...  \n",
       "1  \\n\\t\\tHere’s how to buy the new Google Pixel 3...  \n",
       "2          \\n\\t\\tThe best Pixel 3 cases and covers\\t  \n",
       "3  \\n\\t\\tGoogle Pixel 3 vs. Pixel 2 vs. Pixel: Pi...  \n",
       "4  \\n\\t\\tGoogle Pixel 3 vs. Samsung Galaxy S9: Wh...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View initial data set\n",
    "json_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for standard text cleaning.\n",
    "def text_cleaner(text):\n",
    "    # Visual inspection identifies a form of punctuation spaCy does not\n",
    "    # recognize: the double dash '--'.  Better get rid of it now!\n",
    "\n",
    "    text = str(text).replace(\"\\n\", \"\")\n",
    "    text = str(text).replace(\"\\t\", \"\")\n",
    "    text = str(text).replace(\"\\\\n\", \"\")\n",
    "    text = str(text).replace(\"\\\\t\", \"\")\n",
    "    text = str(text).replace(\"\\\\\", \"\")\n",
    "    text = str(text).replace(\"xa0\", \" \")\n",
    "    text = str(text).replace(\"\\'\", \"\")\n",
    "    text = re.sub(\"<p>\", \"\", str(text))\n",
    "    text = re.sub(\"</p>\", \"\", str(text))\n",
    "    text = re.sub(\"</a>\", \"\", str(text))\n",
    "    text = re.sub('<[^>]+>', \"\", str(text)) \n",
    "    text = str(text).replace(\"\\\\u2019\", \"\")\n",
    "    text = str(text).replace(\"\\\\u2013\", \"\")\n",
    "    text = str(text).replace(\"\\\\u2018\", \"\")\n",
    "    text = str(text).replace(\"\\\\u00a0\", \"\")\n",
    "    text = str(text).replace(\"\\\\u00a3\", \"\")\n",
    "    text = str(text).replace(\"\\u2014\", \"\")\n",
    "    text = str(text).replace(\"\\u201d\", \"\")\n",
    "    text = str(text).replace(\"\\u201c\", \"\")\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to clean text\n",
    "def clean_text(df):\n",
    "    # Convert lists to strings and remove brackets\n",
    "    df['text'] = df['text'].astype(str)\n",
    "    df['author'] = df['author'].astype(str)\n",
    "\n",
    "    df['text'] = df['text'].map(lambda x: x.strip('[]'))\n",
    "    df['author'] = df['author'].map(lambda x: x.strip('[]'))\n",
    "\n",
    "    # Clean text\n",
    "    df['text'] = df['text'].apply(lambda x: text_cleaner(x))\n",
    "    df['title'] = df['title'].apply(lambda x: text_cleaner(x))\n",
    "    df['author'] = df['author'].apply(lambda x: text_cleaner(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Text\n",
    "clean_text(json_data)\n",
    "\n",
    "# Reset index\n",
    "json_data = json_data.reset_index()\n",
    "json_data = json_data.drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Julian Chokkattu</td>\n",
       "      <td>Google’s annual hardware launch event will tak...</td>\n",
       "      <td>Google will announce hardware on October 9, ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Christian de Looper</td>\n",
       "      <td>Google finally unveiled the new Google Pixel 3...</td>\n",
       "      <td>Here’s how to buy the new Google Pixel 3 and G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Simon Hill</td>\n",
       "      <td>If you plan to buy one of Google’s Pixel 3 sma...</td>\n",
       "      <td>The best Pixel 3 cases and covers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Simon Hill</td>\n",
       "      <td>As the developer of Android, Google turns out ...</td>\n",
       "      <td>Google Pixel 3 vs. Pixel 2 vs. Pixel: Picking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Simon Hill</td>\n",
       "      <td>There are plenty of contenders in the Android ...</td>\n",
       "      <td>Google Pixel 3 vs. Samsung Galaxy S9: Which sm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Julian Chokkattu</td>\n",
       "      <td>Got your hands on a new Pixel 3 or Pixel 3 XL ...</td>\n",
       "      <td>Key settings you need to change on your brand-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Simon Hill</td>\n",
       "      <td>Rarely has a flagship phone been so thoroughly...</td>\n",
       "      <td>Google Pixel 3 and Pixel 3 XL: Everything you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lucas Coll</td>\n",
       "      <td>Mobile hardware is getting better and better, ...</td>\n",
       "      <td>Verizon’s buy one, get one offer is the best d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Christian de Looper</td>\n",
       "      <td>The Google Pixel 3 and Pixel 3 XL may have sto...</td>\n",
       "      <td>The Google Pixel Stand turns your Android phon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Simon Hill</td>\n",
       "      <td>The Google Pixel 3 and Pixel 3 XL are phones w...</td>\n",
       "      <td>The best Google Pixel 3 tips and tricks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                author                                               text  \\\n",
       "0     Julian Chokkattu  Google’s annual hardware launch event will tak...   \n",
       "1  Christian de Looper  Google finally unveiled the new Google Pixel 3...   \n",
       "2           Simon Hill  If you plan to buy one of Google’s Pixel 3 sma...   \n",
       "3           Simon Hill  As the developer of Android, Google turns out ...   \n",
       "4           Simon Hill  There are plenty of contenders in the Android ...   \n",
       "5     Julian Chokkattu  Got your hands on a new Pixel 3 or Pixel 3 XL ...   \n",
       "6           Simon Hill  Rarely has a flagship phone been so thoroughly...   \n",
       "7           Lucas Coll  Mobile hardware is getting better and better, ...   \n",
       "8  Christian de Looper  The Google Pixel 3 and Pixel 3 XL may have sto...   \n",
       "9           Simon Hill  The Google Pixel 3 and Pixel 3 XL are phones w...   \n",
       "\n",
       "                                               title  \n",
       "0  Google will announce hardware on October 9, ne...  \n",
       "1  Here’s how to buy the new Google Pixel 3 and G...  \n",
       "2                  The best Pixel 3 cases and covers  \n",
       "3  Google Pixel 3 vs. Pixel 2 vs. Pixel: Picking ...  \n",
       "4  Google Pixel 3 vs. Samsung Galaxy S9: Which sm...  \n",
       "5  Key settings you need to change on your brand-...  \n",
       "6  Google Pixel 3 and Pixel 3 XL: Everything you ...  \n",
       "7  Verizon’s buy one, get one offer is the best d...  \n",
       "8  The Google Pixel Stand turns your Android phon...  \n",
       "9            The best Google Pixel 3 tips and tricks  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize dataframe\n",
    "json_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Process Data for Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process and tokenize the text using Gensim\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc = True))\n",
    "\n",
    "data = list(json_data['text'])\n",
    "data_words = list(sent_to_words(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['google', 'annual', 'hardware', 'launch', 'event', 'will', 'take', 'place', 'on', 'october', 'in', 'new', 'york', 'city', 'the', 'company', 'sent', 'out', 'invites', 'to', 'media', 'including', 'digital', 'trends', 'confirming', 'the', 'date', 'which', 'had', 'leaked', 'in', 'august', 'the', 'date', 'and', 'venue', 'are', 'change', 'of', 'pace', 'considering', 'the', 'past', 'two', 'google', 'october', 'events', 'have', 'taken', 'place', 'in', 'san', 'francisco', 'on', 'october', 'the', 'company', 'is', 'widely', 'expected', 'to', 'launch', 'slew', 'of', 'hardware', 'products', 'ranging', 'from', 'smartphones', 'to', 'smart', 'home', 'devices', 'the', 'highlights', 'will', 'be', 'the', 'pixel', 'and', 'pixel', 'xl', 'successors', 'to', 'last', 'year', 'critically', 'acclaimed', 'pixel', 'and', 'pixel', 'xl', 'smartphones', 'there', 'have', 'been', 'an', 'alarmingly', 'high', 'number', 'of', 'leaks', 'for', 'the', 'pixel', 'series', 'and', 'if', 'true', 'we', 'know', 'quite', 'lot', 'about', 'the', 'phones', 'it', 'may', 'be', 'due', 'to', 'carelessness', 'recently', 'someone', 'left', 'pixel', 'in', 'the', 'back', 'of', 'lyft', 'separately', 'group', 'in', 'russia', 'claims', 'to', 'have', 'gotten', 'its', 'hands', 'on', 'shipment', 'of', 'pixel', 'xl', 'smartphones', 'and', 'even', 'posted', 'an', 'unboxing', 'video', 'showing', 'everything', 'you', 'get', 'in', 'the', 'box', 'the', 'pixel', 'xl', 'is', 'expected', 'to', 'have', 'notch', 'design', 'where', 'cutout', 'at', 'the', 'top', 'of', 'the', 'screen', 'houses', 'the', 'front', 'facing', 'camera', 'this', 'has', 'garnered', 'some', 'criticism', 'as', 'the', 'notch', 'on', 'the', 'pixel', 'xl', 'looks', 'unusually', 'large', 'the', 'smaller', 'pixel', 'may', 'have', 'more', 'traditional', 'design', 'with', 'slimmer', 'bezels', 'on', 'the', 'top', 'and', 'bottom', 'you', 'can', 'learn', 'more', 'about', 'the', 'two', 'phones', 'in', 'our', 'pixel', 'roundup', 'as', 'the', 'new', 'pixel', 'devices', 'are', 'rumored', 'to', 'support', 'wireless', 'charging', 'leaks', 'suggest', 'google', 'will', 'also', 'announce', 'the', 'pixel', 'stand', 'wireless', 'charging', 'dock', 'that', 'also', 'turns', 'the', 'phone', 'screen', 'into', 'smart', 'display', 'for', 'google', 'assistant', 'similar', 'to', 'what', 'lenovo', 'offers', 'with', 'its', 'smart', 'display', 'google', 'is', 'also', 'rumored', 'to', 'be', 'launch', 'its', 'own', 'smart', 'display', 'to', 'compete', 'with', 'the', 'likes', 'of', 'amazon', 'echo', 'show', 'it', 'will', 'essentially', 'be', 'google', 'home', 'with', 'screen', 'you', 'll', 'be', 'able', 'to', 'access', 'youtube', 'videos', 'with', 'your', 'voice', 'thanks', 'to', 'google', 'assistant', 'and', 'make', 'video', 'calls', 'with', 'google', 'duo', 'app', 'other', 'products', 'rumored', 'to', 'be', 'on', 'the', 'docket', 'are', 'two', 'pixelbooks', 'which', 'are', 'chromebooks', 'from', 'google', 'running', 'chrome', 'os', 'and', 'potential', 'followup', 'to', 'the', 'google', 'pixel', 'buds', 'there', 'likely', 'more', 'google', 'will', 'announce', 'at', 'the', 'event', 'that', 'we', 'haven', 'heard', 'much', 'about', 'for', 'example', 'last', 'year', 'google', 'clips', 'announcement', 'came', 'as', 'surprise', 'digital', 'trends', 'will', 'be', 'on', 'the', 'scene', 'in', 'new', 'york', 'on', 'october', 'reporting', 'on', 'everything', 'google', 'will', 'announce', 'so', 'stay', 'tuned']]\n"
     ]
    }
   ],
   "source": [
    "# Visualize tokenized documents\n",
    "print(data_words[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Bigrams and Trigrams\n",
    "\n",
    "# Build the models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100)\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)\n",
    "\n",
    "# fast way to get a sentece clubbed as a bigram/trigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Stopwords, make bigrams and lemmatize\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['pixel', 'iphone', 'samsung', 'apple', 'essential', 'xs', 'max', \n",
    "                  'huawei', 'galaxy', 'note', 'moto', 'oneplus', 'android', 'mate', 'pro', 'lg', 'sony', 'razer', 'phone', 'company', \n",
    "                  'smartphone', 'google', 'thinq', 'nokia', 'htc', 'xperia', 'xz', 'xr', 's9'])\n",
    "\n",
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['annual', 'hardware', 'launch', 'event', 'take', 'place', 'october', 'new', 'york', 'city', 'send', 'invite', 'medium', 'include', 'digital_trend', 'confirm', 'date', 'leak', 'august', 'date', 'venue', 'change', 'pace', 'consider', 'october', 'event', 'take', 'place', 'san', 'francisco', 'october', 'widely', 'expect', 'launch', 'slay', 'hardware', 'product', 'range', 'smartphone', 'smart', 'home', 'device', 'highlight', 'successor', 'last_year', 'critically', 'acclaim', 'smartphone', 'alarmingly', 'high', 'number', 'leak', 'series', 'true', 'know', 'quite', 'lot', 'phone', 'may', 'due', 'carelessness', 'recently', 'someone', 'leave', 'lyft', 'separately', 'group', 'russia', 'claim', 'get', 'hand', 'shipment', 'smartphone', 'even', 'post', 'unbox', 'video', 'show', 'everything', 'get', 'box', 'expect', 'notch', 'design', 'cutout', 'top', 'screen', 'house', 'front_fac', 'camera', 'garner', 'criticism', 'notch', 'look', 'unusually', 'large', 'small', 'may', 'traditional', 'design', 'slim', 'bezel', 'top', 'bottom', 'learn', 'phone', 'roundup', 'new', 'device', 'rumor', 'support', 'wireless_charging', 'leak', 'suggest', 'also', 'announce', 'stand', 'wireless_charging', 'dock', 'also', 'turn', 'screen', 'smart', 'display', 'assistant', 'similar', 'lenovo', 'offer', 'smart', 'display', 'also', 'rumor', 'launch', 'smart', 'display', 'compete', 'like', 'amazon', 'echo', 'show', 'essentially', 'home', 'screen', 'able', 'access', 'youtube', 'video', 'voice', 'thank', 'assistant', 'make', 'video', 'call', 'duo', 'app', 'product', 'rumor', 'docket', 'pixelbook', 'chromebook', 'run', 'chrome_os', 'potential', 'followup', 'bud', 'likely', 'announce', 'event', 'hear', 'much', 'example', 'last_year', 'clip', 'announcement', 'come', 'surprise', 'digital_trend', 'scene', 'new', 'york', 'october', 'report', 'everything', 'announce', 'stay', 'tune']]\n"
     ]
    }
   ],
   "source": [
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Corpus for Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather tfidf scores\n",
    "tfidf = models.TfidfModel(corpus, id2word = id2word)\n",
    "\n",
    "# filter out low value words\n",
    "low_value = 0.025\n",
    "\n",
    "for i in range(0, len(corpus)):\n",
    "    bow = corpus[i]\n",
    "    low_value_words = [] #reinitialize to be safe. You can skip this.\n",
    "    low_value_words = [id for id, value in tfidf[bow] if value < low_value]\n",
    "    new_bow = [b for b in bow if b[0] not in low_value_words]\n",
    "\n",
    "    #reassign        \n",
    "    corpus[i] = new_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (5, 1), (6, 3), (7, 1), (8, 1), (10, 2), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 2), (33, 2), (34, 2), (35, 2), (36, 3), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (44, 3), (45, 2), (46, 1), (47, 2), (48, 1), (49, 1), (50, 1), (51, 1), (53, 1), (54, 1), (55, 2), (56, 1), (57, 1), (58, 1), (59, 2), (60, 1), (62, 1), (65, 2), (66, 3), (67, 3), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (75, 1), (78, 1), (81, 2), (82, 1), (83, 4), (85, 1), (87, 1), (88, 2), (89, 1), (90, 1), (91, 2), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 3), (98, 1), (99, 1), (100, 1), (101, 1), (102, 3), (103, 1), (104, 1), (105, 1), (106, 1), (107, 2), (108, 1), (109, 1), (110, 1), (112, 4), (113, 3), (114, 1), (115, 1), (116, 1), (117, 1), (118, 1), (119, 1), (120, 1), (122, 1), (123, 2), (124, 1), (125, 1), (126, 1), (127, 1), (128, 1), (129, 1), (130, 1), (131, 3), (132, 1), (133, 1), (134, 2), (135, 2), (136, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# View\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the lda topic model\n",
    "lda = models.ldamodel.LdaModel(corpus=corpus, id2word=id2word, num_topics=3, update_every=1, \n",
    "                               chunksize=50, passes=25, random_state=1, alpha='auto', minimum_probability=0)\n",
    "\n",
    "# save the model to disk\n",
    "filename = 'lda_model.pkl'\n",
    "pickle.dump(lda, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.018*\"camera\" + 0.013*\"phone\" + 0.009*\"good\" + 0.008*\"display\" + '\n",
      "  '0.008*\"feature\" + 0.007*\"lens\" + 0.007*\"megapixel\" + 0.006*\"offer\" + '\n",
      "  '0.006*\"winner\" + 0.006*\"find\" + 0.006*\"screen\" + 0.005*\"get\" + '\n",
      "  '0.005*\"device\" + 0.005*\"come\" + 0.005*\"update\"'),\n",
      " (1,\n",
      "  '0.018*\"app\" + 0.017*\"screen\" + 0.014*\"case\" + 0.011*\"tap\" + 0.008*\"home\" + '\n",
      "  '0.007*\"set\" + 0.006*\"want\" + 0.006*\"display\" + 0.006*\"setting\" + '\n",
      "  '0.006*\"option\" + 0.006*\"go\" + 0.006*\"turn\" + 0.006*\"button\" + 0.005*\"use\" + '\n",
      "  '0.005*\"time\"'),\n",
      " (2,\n",
      "  '0.007*\"photo\" + 0.006*\"even\" + 0.006*\"camera\" + 0.006*\"device\" + '\n",
      "  '0.005*\"could\" + 0.004*\"say\" + 0.004*\"take\" + 0.004*\"user\" + 0.004*\"issue\" + '\n",
      "  '0.004*\"really\" + 0.004*\"thing\" + 0.004*\"leak\" + 0.003*\"people\" + '\n",
      "  '0.003*\"new\" + 0.003*\"year\"')]\n"
     ]
    }
   ],
   "source": [
    "# Print the key words in the 10 topics\n",
    "pprint(lda.print_topics(num_words=15))\n",
    "doc_lda = lda[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually Naming Topics\n",
    "\n",
    "1. topic 0: reliability\n",
    "    \n",
    "2. topic 1: function\n",
    "    \n",
    "3. topic 2: design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.3891607445835293\n"
     ]
    }
   ],
   "source": [
    "# Evaluate LDA model by computing Coherence\n",
    "coherenece_model_lda = CoherenceModel(model=lda, texts=data_lemmatized, dictionary=id2word, coherence='c_v' )\n",
    "coherence_lda = coherenece_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating LDA Model\n",
    "\n",
    "One of the biggest problems in developing this pipeline is evaluating the models. This is because almost all of the models are unsupervised. And the one supervised model is trained on labels produced by another unsupervised model! Thankfully there are way to measure the performance of our models.\n",
    "\n",
    "For our LDA model we calculate a coherence score to evaluate how successful our topics are. Intuitively, the coherence score measure how \"coherent\" our topics are to the documents. This basically scores how logically our documents fall under the topics and how similar they are. The highest score I've been able to produce is 0.389, so we can see there is room for improvement. To produce better results in the future, I think we would need to collect aa lot more data (1000 or 2000 documents rather than just 285), but for the sake of this project, time was a bit sensitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/pyLDAvis/_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el1139648351103689210958573\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el1139648351103689210958573_data = {\"mdsDat\": {\"x\": [-0.07700136487516204, -0.1165162515729329, 0.19351761644809484], \"y\": [0.14874059511655094, -0.1297830928252501, -0.018957502291300977], \"topics\": [1, 2, 3], \"cluster\": [1, 1, 1], \"Freq\": [52.019439697265625, 30.86141586303711, 17.119138717651367]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\"], \"Freq\": [345.0, 513.0, 552.0, 245.0, 180.0, 300.0, 303.0, 121.0, 266.0, 166.0, 154.0, 104.0, 179.0, 378.0, 109.0, 213.0, 211.0, 219.0, 208.0, 263.0, 125.0, 164.0, 195.0, 284.0, 416.0, 162.0, 75.0, 184.0, 487.0, 94.0, 552.2993774414062, 299.7100830078125, 265.730712890625, 210.64170837402344, 183.48085021972656, 194.5190887451172, 302.4964294433594, 161.29910278320312, 160.69288635253906, 153.78526306152344, 146.03915405273438, 132.86669921875, 114.75529479980469, 119.50037384033203, 119.58602142333984, 108.60038757324219, 102.64198303222656, 102.7277603149414, 101.27371215820312, 94.13578033447266, 88.15130615234375, 89.14373016357422, 82.64710998535156, 98.76799011230469, 83.11387634277344, 76.87588500976562, 77.68099975585938, 85.74024200439453, 65.66699981689453, 80.6142578125, 272.9447021484375, 105.84123992919922, 372.7113342285156, 160.76931762695312, 336.3608093261719, 803.5830078125, 177.3512725830078, 260.1236267089844, 234.22210693359375, 159.06590270996094, 181.08828735351562, 144.40716552734375, 366.3433532714844, 200.53489685058594, 148.6807098388672, 142.041259765625, 194.89913940429688, 165.96160888671875, 214.18081665039062, 239.7742156982422, 94.11063385009766, 52.2033805847168, 53.82472610473633, 45.983211517333984, 40.503944396972656, 37.51106262207031, 31.253366470336914, 26.613210678100586, 25.45962142944336, 26.50916862487793, 25.398090362548828, 23.53307342529297, 21.131669998168945, 25.163312911987305, 23.247608184814453, 20.24047088623047, 18.755897521972656, 23.17491340637207, 17.62397003173828, 17.518625259399414, 22.36862564086914, 18.924654006958008, 17.332714080810547, 16.581918716430664, 82.46744537353516, 16.65740394592285, 16.141233444213867, 17.44184112548828, 17.49455451965332, 15.306109428405762, 22.127574920654297, 36.562801361083984, 116.35171508789062, 56.35757827758789, 102.36787414550781, 74.60321044921875, 29.285114288330078, 81.06407928466797, 35.903987884521484, 50.38700485229492, 42.92308807373047, 102.40151977539062, 187.17886352539062, 159.06178283691406, 44.62308883666992, 85.60554504394531, 53.20797348022461, 111.0650863647461, 96.67357635498047, 83.54501342773438, 90.04633331298828, 70.95747375488281, 55.02837371826172, 107.29020690917969, 94.42293548583984, 47.454551696777344, 156.01239013671875, 85.98124694824219, 73.5504150390625, 69.12059783935547, 65.4366226196289, 61.42847442626953, 70.64124298095703, 157.244873046875, 64.19927215576172, 86.93098449707031, 67.7859878540039, 60.851661682128906, 57.13307189941406, 52.5621223449707, 33.41038513183594, 22.63145637512207, 27.843835830688477, 27.11930274963379, 36.93698501586914, 18.893089294433594, 18.667552947998047, 22.664060592651367, 17.40412712097168, 17.154621124267578, 19.631418228149414, 15.556203842163086, 16.186054229736328, 17.54962158203125, 18.600566864013672, 13.475279808044434, 15.967215538024902, 12.947906494140625, 11.268660545349121, 11.462236404418945, 55.847652435302734, 9.985919952392578, 9.51968765258789, 10.228094100952148, 60.59353256225586, 11.030817985534668, 21.141775131225586, 9.039228439331055, 8.885663986206055, 164.57077026367188, 67.98735809326172, 30.89336585998535, 16.860380172729492, 29.114784240722656, 88.92823791503906, 36.125030517578125, 195.6945343017578, 96.71778106689453, 252.97177124023438, 21.283117294311523, 81.85394287109375, 54.51569747924805, 108.10238647460938, 240.39810180664062, 50.574546813964844, 27.878389358520508, 26.31231117248535, 86.6415786743164, 31.748647689819336, 83.4102783203125, 58.958045959472656, 80.75543212890625, 46.732418060302734, 74.65667724609375, 90.83480834960938, 78.5782241821289, 60.831825256347656, 73.18102264404297, 39.583309173583984, 66.34144592285156, 89.18172454833984, 38.381290435791016, 42.358463287353516, 42.12146759033203, 41.447940826416016, 41.520484924316406, 41.88520050048828], \"Term\": [\"app\", \"screen\", \"phone\", \"case\", \"tap\", \"megapixel\", \"lens\", \"set\", \"winner\", \"home\", \"option\", \"setting\", \"use\", \"feature\", \"turn\", \"want\", \"come\", \"even\", \"battery\", \"photo\", \"could\", \"go\", \"back\", \"offer\", \"good\", \"button\", \"notification\", \"inch\", \"display\", \"leak\", \"phone\", \"megapixel\", \"winner\", \"come\", \"inch\", \"back\", \"lens\", \"storage\", \"available\", \"ram\", \"flagship\", \"expect\", \"also\", \"gb\", \"premium\", \"mean\", \"processor\", \"aperture\", \"slightly\", \"difference\", \"powerful\", \"mah_battery\", \"deal\", \"bezel\", \"spec\", \"well\", \"late\", \"extra\", \"boast\", \"expensive\", \"offer\", \"pretty\", \"good\", \"support\", \"feature\", \"camera\", \"price\", \"find\", \"get\", \"dual\", \"design\", \"edge\", \"display\", \"update\", \"still\", \"play\", \"new\", \"big\", \"device\", \"screen\", \"leak\", \"pic\", \"rumor\", \"week\", \"hydrogen\", \"reportedly\", \"bug\", \"scooter\", \"patent\", \"source\", \"car\", \"bloomberg\", \"rzr\", \"render\", \"basically\", \"cause\", \"statement\", \"iso\", \"quarter\", \"keyssa\", \"potential\", \"watt\", \"there\", \"allege\", \"report\", \"lawsuit\", \"comment\", \"xa\", \"previously\", \"beer\", \"have\", \"apparently\", \"could\", \"s\", \"issue\", \"accord\", \"development\", \"product\", \"post\", \"cam\", \"ai\", \"user\", \"photo\", \"even\", \"be\", \"seem\", \"sale\", \"say\", \"really\", \"show\", \"people\", \"image\", \"picture\", \"take\", \"thing\", \"try\", \"device\", \"year\", \"feel\", \"way\", \"would\", \"sell\", \"work\", \"camera\", \"shoot\", \"new\", \"look\", \"launch\", \"software\", \"toggle\", \"protector\", \"sleep\", \"office\", \"mouse\", \"disturb\", \"location\", \"siri\", \"bar\", \"repair\", \"scroll\", \"microsoft\", \"headset\", \"settings_gt\", \"timer\", \"disable\", \"screenshot\", \"block\", \"bumper\", \"skype\", \"alarm\", \"icon\", \"luckily\", \"button_cover\", \"album\", \"select\", \"automate\", \"default\", \"slider_next\", \"voip\", \"tap\", \"notification\", \"lock\", \"wallpaper\", \"laptop\", \"setting\", \"swipe\", \"case\", \"set\", \"app\", \"wake\", \"turn\", \"protection\", \"home\", \"screen\", \"open\", \"music\", \"slider\", \"option\", \"protect\", \"go\", \"allow\", \"button\", \"choose\", \"time\", \"want\", \"use\", \"light\", \"mode\", \"easy\", \"battery\", \"display\", \"automatically\", \"call\", \"work\", \"add\", \"photo\", \"feature\"], \"Total\": [345.0, 513.0, 552.0, 245.0, 180.0, 300.0, 303.0, 121.0, 266.0, 166.0, 154.0, 104.0, 179.0, 378.0, 109.0, 213.0, 211.0, 219.0, 208.0, 263.0, 125.0, 164.0, 195.0, 284.0, 416.0, 162.0, 75.0, 184.0, 487.0, 94.0, 552.8980102539062, 300.3186950683594, 266.31292724609375, 211.2418212890625, 184.1152801513672, 195.2288055419922, 303.6379699707031, 161.91122436523438, 161.31216430664062, 154.41400146484375, 146.66522216796875, 133.49557495117188, 115.33345794677734, 120.11832427978516, 120.25556182861328, 109.24505615234375, 103.2581558227539, 103.34568786621094, 101.90898895263672, 94.73295593261719, 88.74430084228516, 89.7692642211914, 83.27385711669922, 99.53145599365234, 83.80134582519531, 77.52963256835938, 78.35784149169922, 86.4959945678711, 66.26284790039062, 81.36225891113281, 284.8952331542969, 108.74958038330078, 416.71136474609375, 170.03500366210938, 378.58441162109375, 979.713134765625, 190.1666259765625, 292.43743896484375, 260.8150329589844, 172.18043518066406, 203.3314971923828, 156.41305541992188, 487.66583251953125, 245.53717041015625, 170.7345733642578, 162.09017944335938, 282.21783447265625, 217.11856079101562, 384.4122619628906, 513.9652099609375, 94.80314636230469, 52.82826614379883, 54.47346115112305, 46.63557815551758, 41.10313415527344, 38.13361740112305, 31.89274024963379, 27.213960647583008, 26.076440811157227, 27.17951774597168, 26.058652877807617, 24.14949607849121, 21.730852127075195, 25.877126693725586, 23.943098068237305, 20.8691463470459, 19.37311363220215, 23.953210830688477, 18.23133659362793, 18.124248504638672, 23.192581176757812, 19.622495651245117, 17.9736385345459, 17.19521141052246, 85.53197479248047, 17.28428840637207, 16.755735397338867, 18.124860763549805, 18.19264030456543, 15.926485061645508, 23.0806941986084, 38.45167922973633, 125.48918151855469, 59.90375900268555, 110.18250274658203, 81.23379516601562, 30.935182571411133, 89.64710235595703, 38.65501022338867, 55.94806671142578, 47.72164535522461, 126.15089416503906, 263.1915283203125, 219.56126403808594, 51.4013786315918, 111.90221405029297, 64.44856262207031, 159.49417114257812, 136.88536071777344, 114.52678680419922, 126.0068588256836, 93.8116683959961, 68.39308166503906, 168.7471923828125, 158.4709014892578, 59.54074478149414, 384.4122619628906, 152.1488037109375, 121.3897476196289, 112.11383056640625, 103.54025268554688, 94.50634002685547, 130.98641967773438, 979.713134765625, 108.78630828857422, 282.21783447265625, 173.0481414794922, 165.50640869140625, 142.1645050048828, 53.20756149291992, 34.04216003417969, 23.26616668701172, 28.637575149536133, 27.893726348876953, 38.149627685546875, 19.54892921447754, 19.31861686706543, 23.47205924987793, 18.049888610839844, 17.801366806030273, 20.393815994262695, 16.195331573486328, 16.852510452270508, 18.28556251525879, 19.441972732543945, 14.106138229370117, 16.755327224731445, 13.602660179138184, 11.90042495727539, 12.170602798461914, 59.48203659057617, 10.6361083984375, 10.154831886291504, 10.92301082611084, 64.74641418457031, 11.789134979248047, 22.61020278930664, 9.66887378692627, 9.514960289001465, 180.58128356933594, 75.47417449951172, 33.91883087158203, 18.238433837890625, 32.195953369140625, 104.45841217041016, 40.60533142089844, 245.1908416748047, 121.3241958618164, 345.984375, 23.645179748535156, 109.44084167480469, 71.00898742675781, 166.89163208007812, 513.9652099609375, 71.83599853515625, 33.58769989013672, 31.27554702758789, 154.6784210205078, 40.6948127746582, 164.1509246826172, 102.03541564941406, 162.6649932861328, 74.44872283935547, 152.47640991210938, 213.57296752929688, 179.74688720703125, 123.71080017089844, 179.36495971679688, 60.52703094482422, 208.4365692138672, 487.66583251953125, 63.56278991699219, 102.68014526367188, 130.98641967773438, 128.41944885253906, 263.1915283203125, 378.58441162109375], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.6524999737739563, 0.6514999866485596, 0.6514000296592712, 0.6506999731063843, 0.6500999927520752, 0.6499000191688538, 0.6498000025749207, 0.6498000025749207, 0.6496999859809875, 0.6495000123977661, 0.6492999792098999, 0.6488000154495239, 0.6485000252723694, 0.6484000086784363, 0.6480000019073486, 0.647599995136261, 0.647599995136261, 0.647599995136261, 0.6473000049591064, 0.6471999883651733, 0.6467999815940857, 0.6466000080108643, 0.6460000276565552, 0.6459000110626221, 0.6452999711036682, 0.6450999975204468, 0.6449000239372253, 0.6448000073432922, 0.6445000171661377, 0.6442999839782715, 0.6107000112533569, 0.6263999938964844, 0.5419999957084656, 0.5975000262260437, 0.5353000164031982, 0.4553999900817871, 0.5838000178337097, 0.5364999771118164, 0.5460000038146973, 0.5742999911308289, 0.5376999974250793, 0.5737000107765198, 0.3675000071525574, 0.4510999917984009, 0.5152000188827515, 0.5214999914169312, 0.2833999991416931, 0.3849000036716461, 0.06870000064373016, -0.10890000313520432, 1.1683000326156616, 1.1638000011444092, 1.163699984550476, 1.1615999937057495, 1.1610000133514404, 1.1591999530792236, 1.155400037765503, 1.1533000469207764, 1.1517000198364258, 1.1506999731063843, 1.149999976158142, 1.1497999429702759, 1.1476999521255493, 1.1476999521255493, 1.1461999416351318, 1.1450999975204468, 1.1433000564575195, 1.1426000595092773, 1.141800045967102, 1.141700029373169, 1.1395000219345093, 1.1395000219345093, 1.1394000053405762, 1.139299988746643, 1.13919997215271, 1.138700008392334, 1.1382999420166016, 1.1373000144958496, 1.1365000009536743, 1.1359000205993652, 1.1334999799728394, 1.1253000497817993, 1.100100040435791, 1.1145999431610107, 1.1021000146865845, 1.090499997138977, 1.1208000183105469, 1.0750000476837158, 1.1017999649047852, 1.0709999799728394, 1.069700002670288, 0.9671000242233276, 0.8348000049591064, 0.8532999753952026, 1.0341999530792236, 0.907800018787384, 0.984000027179718, 0.8137999773025513, 0.8278999924659729, 0.8601999878883362, 0.8396999835968018, 0.8964999914169312, 0.9581999778747559, 0.7228000164031982, 0.6578999757766724, 0.9488000273704529, 0.27390000224113464, 0.6049000024795532, 0.6746000051498413, 0.6919999718666077, 0.7167999744415283, 0.7448999881744385, 0.5582000017166138, -0.6538000106811523, 0.6482999920845032, -0.0019000000320374966, 0.23839999735355377, 0.17509999871253967, 0.26409998536109924, 1.7527999877929688, 1.7461999654769897, 1.7373000383377075, 1.736899971961975, 1.736799955368042, 1.732699990272522, 1.7308000326156616, 1.7307000160217285, 1.7299000024795532, 1.7285000085830688, 1.7280000448226929, 1.7268999814987183, 1.7246999740600586, 1.7245999574661255, 1.7238999605178833, 1.7207000255584717, 1.7192000150680542, 1.7167999744415283, 1.7156000137329102, 1.7103999853134155, 1.7050000429153442, 1.7019000053405762, 1.7019000053405762, 1.7003999948501587, 1.6992000341415405, 1.698699951171875, 1.6985000371932983, 1.6978000402450562, 1.69760000705719, 1.6964999437332153, 1.6720999479293823, 1.6605000495910645, 1.6714999675750732, 1.686400055885315, 1.6643999814987183, 1.6039999723434448, 1.6481000185012817, 1.5394999980926514, 1.5383000373840332, 1.4519000053405762, 1.6597000360488892, 1.4744999408721924, 1.5006999969482422, 1.3307000398635864, 1.0051000118255615, 1.4140000343322754, 1.5786999464035034, 1.5922000408172607, 1.1854000091552734, 1.516700029373169, 1.0880000591278076, 1.2165000438690186, 1.0647000074386597, 1.299299955368042, 1.0508999824523926, 0.9100000262260437, 0.9375, 1.0550999641418457, 0.8684999942779541, 1.3402999639511108, 0.620199978351593, 0.06599999964237213, 1.2604999542236328, 0.8794999718666077, 0.6304000020027161, 0.6341000199317932, -0.08169999718666077, -0.43650001287460327], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.366499900817871, -4.977799892425537, -5.098100185394287, -5.330399990081787, -5.468500137329102, -5.410099983215332, -4.968500137329102, -5.597300052642822, -5.601099967956543, -5.644999980926514, -5.696700096130371, -5.791200160980225, -5.93779993057251, -5.897299766540527, -5.896500110626221, -5.9928998947143555, -6.049300193786621, -6.048500061035156, -6.06279993057251, -6.135799884796143, -6.201499938964844, -6.190299987792969, -6.265999794006348, -6.087800025939941, -6.26039981842041, -6.338399887084961, -6.328000068664551, -6.229300022125244, -6.495999813079834, -6.290900230407715, -5.071300029754639, -6.018599987030029, -4.759799957275391, -5.600599765777588, -4.862400054931641, -3.991499900817871, -5.502399921417236, -5.1194000244140625, -5.224299907684326, -5.611299991607666, -5.481599807739258, -5.707900047302246, -4.7769999504089355, -5.3796000480651855, -5.678800106048584, -5.7245001792907715, -5.408100128173828, -5.56879997253418, -5.313799858093262, -5.200900077819824, -5.613999843597412, -6.2032999992370605, -6.172699928283691, -6.3302001953125, -6.457099914550781, -6.53380012512207, -6.716300010681152, -6.877099990844727, -6.92140007019043, -6.88100004196167, -6.923799991607666, -7.000100135803223, -7.107699871063232, -6.93310022354126, -7.01230001449585, -7.1508002281188965, -7.2270002365112305, -7.015399932861328, -7.2891998291015625, -7.295199871063232, -7.05079984664917, -7.2179999351501465, -7.3059000968933105, -7.350200176239014, -5.746099948883057, -7.345600128173828, -7.377099990844727, -7.299600124359131, -7.296599864959717, -7.430200099945068, -7.061600208282471, -6.5594000816345215, -5.401899814605713, -6.126800060272217, -5.529900074005127, -5.84630012512207, -6.781400203704834, -5.763199806213379, -6.577600002288818, -6.238699913024902, -6.399099826812744, -5.529600143432617, -4.926400184631348, -5.089200019836426, -6.360199928283691, -5.708700180053711, -6.184299945831299, -5.448400020599365, -5.587100028991699, -5.733099937438965, -5.658100128173828, -5.896399974822998, -6.150599956512451, -5.482900142669678, -5.6107001304626465, -6.298699855804443, -5.108500003814697, -5.7042999267578125, -5.860499858856201, -5.922599792480469, -5.977399826049805, -6.040599822998047, -5.900899887084961, -5.1006999015808105, -5.996500015258789, -5.693399906158447, -5.9421000480651855, -6.050000190734863, -6.113100051879883, -5.6072001457214355, -6.060299873352051, -6.44980001449585, -6.242499828338623, -6.268899917602539, -5.95989990234375, -6.63040018081665, -6.642399787902832, -6.448400020599365, -6.712500095367432, -6.726900100708008, -6.5920000076293945, -6.824699878692627, -6.784999847412109, -6.704100131988525, -6.645999908447266, -6.968299865722656, -6.798600196838379, -7.008200168609619, -7.14709997177124, -7.130099773406982, -5.546500205993652, -7.26800012588501, -7.315800189971924, -7.24399995803833, -5.465000152587891, -7.168499946594238, -6.517899990081787, -7.367599964141846, -7.384699821472168, -4.465799808502197, -5.349800109863281, -6.138599872589111, -6.744200229644775, -6.19789981842041, -5.081299781799316, -5.9822001457214355, -4.292600154876709, -4.997399806976318, -4.035900115966797, -6.511199951171875, -5.1641998291015625, -5.570700168609619, -4.886099815368652, -4.086900234222412, -5.645699977874756, -6.241300106048584, -6.299099922180176, -5.107399940490723, -6.111299991607666, -5.145400047302246, -5.492300033569336, -5.177700042724609, -5.724699974060059, -5.25629997253418, -5.060100078582764, -5.205100059509277, -5.460999965667725, -5.276199817657471, -5.8907999992370605, -5.374300003051758, -5.078499794006348, -5.921599864959717, -5.822999954223633, -5.82859992980957, -5.844699859619141, -5.8429999351501465, -5.834199905395508]}, \"token.table\": {\"Topic\": [1, 2, 1, 3, 1, 2, 3, 3, 2, 1, 3, 1, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 1, 3, 2, 1, 3, 2, 3, 2, 1, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 3, 1, 2, 3, 1, 2, 1, 2, 3, 2, 1, 2, 3, 2, 1, 3, 1, 2, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 3, 1, 3, 1, 2, 3, 1, 3, 1, 2, 1, 3, 1, 3, 1, 2, 1, 1, 1, 1, 3, 1, 2, 1, 3, 1, 1, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 3, 1, 2, 3, 2, 1, 3, 1, 2, 3, 1, 1, 2, 1, 2, 2, 1, 3, 1, 1, 2, 3, 2, 2, 1, 2, 1, 2, 3, 3, 1, 3, 1, 2, 3, 3, 1, 1, 1, 3, 1, 2, 3, 3, 1, 2, 3, 1, 2, 1, 2, 3, 1, 3, 3, 1, 3, 1, 3, 2, 1, 2, 3, 1, 1, 2, 3, 2, 1, 2, 1, 2, 3, 2, 3, 2, 1, 1, 1, 3, 2, 1, 2, 1, 1, 2, 1, 2, 3, 1, 3, 3, 2, 1, 1, 2, 2, 3, 1, 2, 3, 2, 2, 2, 2, 3, 1, 2, 1, 2, 2, 1, 2, 3, 3, 3, 1, 2, 1, 3, 1, 2, 1, 3, 1, 3, 3, 1, 2, 3, 1, 2, 3, 3, 3, 3, 1, 2, 3, 3, 1, 1, 2, 2, 1, 2, 1, 2, 1, 1, 2, 1, 3, 1, 2, 1, 3, 2, 1, 2, 1, 2, 3, 3, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 2, 3, 1, 3, 1, 2, 3, 2, 1, 2, 3, 2, 1, 1, 1, 2, 3, 1, 2, 3, 2, 1, 2], \"Freq\": [0.07386088371276855, 0.9232610464096069, 0.6774674654006958, 0.31926628947257996, 0.10477425903081894, 0.9010586142539978, 0.9038171768188477, 0.9154984951019287, 0.9886473417282104, 0.4214223027229309, 0.578230619430542, 0.9971087574958801, 0.9966550469398499, 0.23989522457122803, 0.028903039172291756, 0.7312468886375427, 0.0520133338868618, 0.9622466564178467, 0.9330624938011169, 0.09439484775066376, 0.2989170253276825, 0.597834050655365, 0.9980648159980774, 0.9988279938697815, 0.9798884391784668, 0.9606108665466309, 0.6812624335289001, 0.316643089056015, 0.8754628896713257, 0.11672838777303696, 0.9418274164199829, 0.9946604371070862, 0.7645592093467712, 0.23489470779895782, 0.9549201726913452, 0.9938095808029175, 0.996033251285553, 0.9720080494880676, 0.955695390701294, 0.3319706320762634, 0.1721329241991043, 0.49795594811439514, 0.984752893447876, 0.3603422939777374, 0.22399656474590302, 0.40903720259666443, 0.08936858922243118, 0.8936859369277954, 0.8206483721733093, 0.16025099158287048, 0.019393431022763252, 0.9593742489814758, 0.1876089721918106, 0.01631382293999195, 0.7993773221969604, 0.9583525657653809, 0.36266571283340454, 0.6313070058822632, 0.9988552331924438, 0.9548969268798828, 0.07171933352947235, 0.9243824481964111, 0.9967113733291626, 0.04422781988978386, 0.9287842512130737, 0.8901719450950623, 0.0737711563706398, 0.03934461623430252, 0.03232565522193909, 0.9374439716339111, 0.556693971157074, 0.4058143198490143, 0.03641923516988754, 0.9922628998756409, 0.9772670865058899, 0.7505139112472534, 0.06561870127916336, 0.18250201642513275, 0.026212574914097786, 0.9698653221130371, 0.9234498739242554, 0.0755021870136261, 0.3469524085521698, 0.6608617305755615, 0.9206392765045166, 0.07671993970870972, 0.27327224612236023, 0.7241714596748352, 0.9962877035140991, 0.9955475926399231, 0.9942656755447388, 0.8875167369842529, 0.11093959212303162, 0.39542055130004883, 0.6096066832542419, 0.8890790343284607, 0.10942511260509491, 0.9954643249511719, 0.9990149140357971, 0.8971875309944153, 0.0038341348990797997, 0.09968750178813934, 0.2254023253917694, 0.2680460214614868, 0.505632221698761, 0.8951039910316467, 0.10558867454528809, 0.043326254934072495, 0.9531775712966919, 0.9879390001296997, 0.14380589127540588, 0.20971693098545074, 0.6471264958381653, 0.9974908232688904, 0.050435394048690796, 0.9414607286453247, 0.21319308876991272, 0.7568354606628418, 0.03197896480560303, 0.9939424991607666, 0.041748058050870895, 0.9602053165435791, 0.07260680943727493, 0.9257368445396423, 0.9931446313858032, 0.09317941218614578, 0.9007343053817749, 0.9954332113265991, 0.5619117617607117, 0.36856579780578613, 0.0664626806974411, 0.9835522174835205, 0.9915282726287842, 0.994605541229248, 0.0032933957409113646, 0.2505844235420227, 0.25866779685020447, 0.49308547377586365, 0.9719202518463135, 0.08844644576311111, 0.9139465689659119, 0.5547589063644409, 0.3929542303085327, 0.052008647471666336, 0.9401934742927551, 0.9914306402206421, 0.997756838798523, 0.998938798904419, 0.9806894659996033, 0.3791152834892273, 0.21185855567455292, 0.4069914221763611, 0.9679595828056335, 0.0297728031873703, 0.1488640159368515, 0.8336384892463684, 0.690955638885498, 0.30827251076698303, 0.039748694747686386, 0.05299825966358185, 0.900970458984375, 0.9582470059394836, 0.04212074726819992, 0.9777364134788513, 0.2923325300216675, 0.7099504470825195, 0.43962177634239197, 0.562457263469696, 0.958719789981842, 0.27776265144348145, 0.7142468094825745, 0.007936076261103153, 0.9983758330345154, 0.12918348610401154, 0.710509181022644, 0.15957960486412048, 0.9843215346336365, 0.19007770717144012, 0.8041749000549316, 0.8760555386543274, 0.024677621200680733, 0.09871048480272293, 0.9313152432441711, 0.051739733666181564, 0.9485791921615601, 0.99161297082901, 0.9978748559951782, 0.9747164249420166, 0.0275863129645586, 0.9344438314437866, 0.9307627081871033, 0.06310255825519562, 0.9974998831748962, 0.08923880010843277, 0.9035428762435913, 0.1965852528810501, 0.024573156610131264, 0.7863410115242004, 0.22532358765602112, 0.7745498418807983, 0.9693862199783325, 0.987311065196991, 0.9973188638687134, 0.2922153174877167, 0.7086221575737, 0.9661041498184204, 0.9418340921401978, 0.023383067920804024, 0.9587057828903198, 0.011691533960402012, 0.9964960813522339, 0.9913083910942078, 0.9663680195808411, 0.9348328113555908, 0.050080329179763794, 0.1706787496805191, 0.8223612308502197, 0.30095145106315613, 0.6959502100944519, 0.9921378493309021, 0.466957688331604, 0.06615233421325684, 0.466957688331604, 0.9215846061706543, 0.9549828767776489, 0.23234571516513824, 0.768528163433075, 0.061779484152793884, 0.9421371221542358, 0.34918293356895447, 0.6454593539237976, 0.1978171020746231, 0.7995107769966125, 0.143597811460495, 0.8520137071609497, 0.9494134187698364, 0.30334699153900146, 0.5883093476295471, 0.10111566632986069, 0.20082637667655945, 0.7334528565406799, 0.06985265761613846, 0.9835072755813599, 0.9243367314338684, 0.988559901714325, 0.031973861157894135, 0.12789544463157654, 0.8313204050064087, 0.93082195520401, 0.9910804033279419, 0.5978989005088806, 0.40094396471977234, 0.9933950901031494, 0.9904375672340393, 0.9807406663894653, 0.8726996183395386, 0.12885497510433197, 0.9943720698356628, 0.9468638896942139, 0.05293027684092522, 0.09850922971963882, 0.8865830898284912, 0.3614875078201294, 0.6340846419334412, 0.08860275894403458, 0.9137159585952759, 0.9458296298980713, 0.4038596451282501, 0.5931688547134399, 0.3475947380065918, 0.1639597862958908, 0.4918793737888336, 0.9843831658363342, 0.9960989952087402, 0.16795220971107483, 0.7893754243850708, 0.033590443432331085, 0.20102185010910034, 0.04568678140640259, 0.7492632269859314, 0.8186133503913879, 0.11403568834066391, 0.06923595070838928, 0.5619012713432312, 0.4395069181919098, 0.18232133984565735, 0.8085554838180542, 0.9458788633346558, 0.0845838338136673, 0.888130247592926, 0.05482926964759827, 0.9320975542068481, 0.4869530200958252, 0.08896256983280182, 0.42608389258384705, 0.9682764410972595, 0.13379259407520294, 0.6154459118843079, 0.249746173620224, 0.9863713979721069, 0.9931686520576477, 0.998824954032898, 0.13741882145404816, 0.5420409440994263, 0.32064393162727356, 0.3283747136592865, 0.6277751922607422, 0.03863231837749481, 0.9379382133483887, 0.4337858557701111, 0.5652361512184143], \"Term\": [\"accord\", \"accord\", \"add\", \"add\", \"ai\", \"ai\", \"alarm\", \"album\", \"allege\", \"allow\", \"allow\", \"also\", \"aperture\", \"app\", \"app\", \"app\", \"apparently\", \"apparently\", \"automate\", \"automatically\", \"automatically\", \"automatically\", \"available\", \"back\", \"bar\", \"basically\", \"battery\", \"battery\", \"be\", \"be\", \"beer\", \"bezel\", \"big\", \"big\", \"block\", \"bloomberg\", \"boast\", \"bug\", \"bumper\", \"button\", \"button\", \"button\", \"button_cover\", \"call\", \"call\", \"call\", \"cam\", \"cam\", \"camera\", \"camera\", \"camera\", \"car\", \"case\", \"case\", \"case\", \"cause\", \"choose\", \"choose\", \"come\", \"comment\", \"could\", \"could\", \"deal\", \"default\", \"default\", \"design\", \"design\", \"design\", \"development\", \"development\", \"device\", \"device\", \"device\", \"difference\", \"disable\", \"display\", \"display\", \"display\", \"disturb\", \"disturb\", \"dual\", \"dual\", \"easy\", \"easy\", \"edge\", \"edge\", \"even\", \"even\", \"expect\", \"expensive\", \"extra\", \"feature\", \"feature\", \"feel\", \"feel\", \"find\", \"find\", \"flagship\", \"gb\", \"get\", \"get\", \"get\", \"go\", \"go\", \"go\", \"good\", \"good\", \"have\", \"have\", \"headset\", \"home\", \"home\", \"home\", \"hydrogen\", \"icon\", \"icon\", \"image\", \"image\", \"image\", \"inch\", \"iso\", \"iso\", \"issue\", \"issue\", \"keyssa\", \"laptop\", \"laptop\", \"late\", \"launch\", \"launch\", \"launch\", \"lawsuit\", \"leak\", \"lens\", \"lens\", \"light\", \"light\", \"light\", \"location\", \"lock\", \"lock\", \"look\", \"look\", \"look\", \"luckily\", \"mah_battery\", \"mean\", \"megapixel\", \"microsoft\", \"mode\", \"mode\", \"mode\", \"mouse\", \"music\", \"music\", \"music\", \"new\", \"new\", \"notification\", \"notification\", \"notification\", \"offer\", \"offer\", \"office\", \"open\", \"open\", \"option\", \"option\", \"patent\", \"people\", \"people\", \"people\", \"phone\", \"photo\", \"photo\", \"photo\", \"pic\", \"picture\", \"picture\", \"play\", \"play\", \"play\", \"post\", \"post\", \"potential\", \"powerful\", \"premium\", \"pretty\", \"pretty\", \"previously\", \"price\", \"price\", \"processor\", \"product\", \"product\", \"protect\", \"protect\", \"protect\", \"protection\", \"protection\", \"protector\", \"quarter\", \"ram\", \"really\", \"really\", \"render\", \"repair\", \"report\", \"report\", \"report\", \"reportedly\", \"rumor\", \"rzr\", \"s\", \"s\", \"sale\", \"sale\", \"say\", \"say\", \"scooter\", \"screen\", \"screen\", \"screen\", \"screenshot\", \"scroll\", \"seem\", \"seem\", \"select\", \"select\", \"sell\", \"sell\", \"set\", \"set\", \"setting\", \"setting\", \"settings_gt\", \"shoot\", \"shoot\", \"shoot\", \"show\", \"show\", \"show\", \"siri\", \"skype\", \"sleep\", \"slider\", \"slider\", \"slider\", \"slider_next\", \"slightly\", \"software\", \"software\", \"source\", \"spec\", \"statement\", \"still\", \"still\", \"storage\", \"support\", \"support\", \"swipe\", \"swipe\", \"take\", \"take\", \"tap\", \"tap\", \"there\", \"thing\", \"thing\", \"time\", \"time\", \"time\", \"timer\", \"toggle\", \"try\", \"try\", \"try\", \"turn\", \"turn\", \"turn\", \"update\", \"update\", \"update\", \"use\", \"use\", \"user\", \"user\", \"voip\", \"wake\", \"wake\", \"wallpaper\", \"wallpaper\", \"want\", \"want\", \"want\", \"watt\", \"way\", \"way\", \"way\", \"week\", \"well\", \"winner\", \"work\", \"work\", \"work\", \"would\", \"would\", \"would\", \"xa\", \"year\", \"year\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 3, 2]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el1139648351103689210958573\", ldavis_el1139648351103689210958573_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el1139648351103689210958573\", ldavis_el1139648351103689210958573_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el1139648351103689210958573\", ldavis_el1139648351103689210958573_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "0     -0.077001  0.148741       1        1  52.019440\n",
       "2     -0.116516 -0.129783       2        1  30.861416\n",
       "1      0.193518 -0.018958       3        1  17.119139, topic_info=     Category        Freq           Term       Total  loglift  logprob\n",
       "term                                                                  \n",
       "9     Default  345.000000            app  345.000000  30.0000  30.0000\n",
       "102   Default  513.000000         screen  513.000000  29.0000  29.0000\n",
       "86    Default  552.000000          phone  552.000000  28.0000  28.0000\n",
       "145   Default  245.000000           case  245.000000  27.0000  27.0000\n",
       "658   Default  180.000000            tap  180.000000  26.0000  26.0000\n",
       "568   Default  300.000000      megapixel  300.000000  25.0000  25.0000\n",
       "337   Default  303.000000           lens  303.000000  24.0000  24.0000\n",
       "193   Default  121.000000            set  121.000000  23.0000  23.0000\n",
       "675   Default  266.000000         winner  266.000000  22.0000  22.0000\n",
       "59    Default  166.000000           home  166.000000  21.0000  21.0000\n",
       "362   Default  154.000000         option  154.000000  20.0000  20.0000\n",
       "981   Default  104.000000        setting  104.000000  19.0000  19.0000\n",
       "464   Default  179.000000            use  179.000000  18.0000  18.0000\n",
       "158   Default  378.000000        feature  378.000000  17.0000  17.0000\n",
       "127   Default  109.000000           turn  109.000000  16.0000  16.0000\n",
       "469   Default  213.000000           want  213.000000  15.0000  15.0000\n",
       "25    Default  211.000000           come  211.000000  14.0000  14.0000\n",
       "43    Default  219.000000           even  219.000000  13.0000  13.0000\n",
       "488   Default  208.000000        battery  208.000000  12.0000  12.0000\n",
       "581   Default  263.000000          photo  263.000000  11.0000  11.0000\n",
       "253   Default  125.000000          could  125.000000  10.0000  10.0000\n",
       "308   Default  164.000000             go  164.000000   9.0000   9.0000\n",
       "223   Default  195.000000           back  195.000000   8.0000   8.0000\n",
       "84    Default  284.000000          offer  284.000000   7.0000   7.0000\n",
       "309   Default  416.000000           good  416.000000   6.0000   6.0000\n",
       "238   Default  162.000000         button  162.000000   5.0000   5.0000\n",
       "949   Default   75.000000   notification   75.000000   4.0000   4.0000\n",
       "326   Default  184.000000           inch  184.000000   3.0000   3.0000\n",
       "36    Default  487.000000        display  487.000000   2.0000   2.0000\n",
       "67    Default   94.000000           leak   94.000000   1.0000   1.0000\n",
       "...       ...         ...            ...         ...      ...      ...\n",
       "193    Topic3   96.717781            set  121.324196   1.5383  -4.9974\n",
       "9      Topic3  252.971771            app  345.984375   1.4519  -4.0359\n",
       "1227   Topic3   21.283117           wake   23.645180   1.6597  -6.5112\n",
       "127    Topic3   81.853943           turn  109.440842   1.4745  -5.1642\n",
       "388    Topic3   54.515697     protection   71.008987   1.5007  -5.5707\n",
       "59     Topic3  108.102386           home  166.891632   1.3307  -4.8861\n",
       "102    Topic3  240.398102         screen  513.965210   1.0051  -4.0869\n",
       "575    Topic3   50.574547           open   71.835999   1.4140  -5.6457\n",
       "942    Topic3   27.878389          music   33.587700   1.5787  -6.2413\n",
       "989    Topic3   26.312311         slider   31.275547   1.5922  -6.2991\n",
       "362    Topic3   86.641579         option  154.678421   1.1854  -5.1074\n",
       "387    Topic3   31.748648        protect   40.694813   1.5167  -6.1113\n",
       "308    Topic3   83.410278             go  164.150925   1.0880  -5.1454\n",
       "480    Topic3   58.958046          allow  102.035416   1.2165  -5.4923\n",
       "238    Topic3   80.755432         button  162.664993   1.0647  -5.1777\n",
       "505    Topic3   46.732418         choose   74.448723   1.2993  -5.7247\n",
       "199    Topic3   74.656677           time  152.476410   1.0509  -5.2563\n",
       "469    Topic3   90.834808           want  213.572968   0.9100  -5.0601\n",
       "464    Topic3   78.578224            use  179.746887   0.9375  -5.2051\n",
       "338    Topic3   60.831825          light  123.710800   1.0551  -5.4610\n",
       "763    Topic3   73.181023           mode  179.364960   0.8685  -5.2762\n",
       "267    Topic3   39.583309           easy   60.527031   1.3403  -5.8908\n",
       "488    Topic3   66.341446        battery  208.436569   0.6202  -5.3743\n",
       "36     Topic3   89.181725        display  487.665833   0.0660  -5.0785\n",
       "864    Topic3   38.381290  automatically   63.562790   1.2605  -5.9216\n",
       "16     Topic3   42.358463           call  102.680145   0.8795  -5.8230\n",
       "476    Topic3   42.121468           work  130.986420   0.6304  -5.8286\n",
       "137    Topic3   41.447941            add  128.419449   0.6341  -5.8447\n",
       "581    Topic3   41.520485          photo  263.191528  -0.0817  -5.8430\n",
       "158    Topic3   41.885201        feature  378.584412  -0.4365  -5.8342\n",
       "\n",
       "[217 rows x 6 columns], token_table=      Topic      Freq           Term\n",
       "term                                \n",
       "847       1  0.073861         accord\n",
       "847       2  0.923261         accord\n",
       "137       1  0.677467            add\n",
       "137       3  0.319266            add\n",
       "1529      1  0.104774             ai\n",
       "1529      2  0.901059             ai\n",
       "853       3  0.903817          alarm\n",
       "854       3  0.915498          album\n",
       "1769      2  0.988647         allege\n",
       "480       1  0.421422          allow\n",
       "480       3  0.578231          allow\n",
       "4         1  0.997109           also\n",
       "1022      1  0.996655       aperture\n",
       "9         1  0.239895            app\n",
       "9         2  0.028903            app\n",
       "9         3  0.731247            app\n",
       "1463      1  0.052013     apparently\n",
       "1463      2  0.962247     apparently\n",
       "3284      3  0.933062       automate\n",
       "864       1  0.094395  automatically\n",
       "864       2  0.298917  automatically\n",
       "864       3  0.597834  automatically\n",
       "139       1  0.998065      available\n",
       "223       1  0.998828           back\n",
       "865       3  0.979888            bar\n",
       "1030      2  0.960611      basically\n",
       "488       1  0.681262        battery\n",
       "488       3  0.316643        battery\n",
       "3954      2  0.875463             be\n",
       "3954      3  0.116728             be\n",
       "...     ...       ...            ...\n",
       "205       2  0.114036         update\n",
       "205       3  0.069236         update\n",
       "464       1  0.561901            use\n",
       "464       3  0.439507            use\n",
       "1159      1  0.182321           user\n",
       "1159      2  0.808555           user\n",
       "7382      3  0.945879           voip\n",
       "1227      2  0.084584           wake\n",
       "1227      3  0.888130           wake\n",
       "1014      1  0.054829      wallpaper\n",
       "1014      3  0.932098      wallpaper\n",
       "469       1  0.486953           want\n",
       "469       2  0.088963           want\n",
       "469       3  0.426084           want\n",
       "1426      2  0.968276           watt\n",
       "471       1  0.133793            way\n",
       "471       2  0.615446            way\n",
       "471       3  0.249746            way\n",
       "1340      2  0.986371           week\n",
       "473       1  0.993169           well\n",
       "675       1  0.998825         winner\n",
       "476       1  0.137419           work\n",
       "476       2  0.542041           work\n",
       "476       3  0.320644           work\n",
       "212       1  0.328375          would\n",
       "212       2  0.627775          would\n",
       "212       3  0.038632          would\n",
       "7721      2  0.937938             xa\n",
       "677       1  0.433786           year\n",
       "677       2  0.565236           year\n",
       "\n",
       "[311 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 3, 2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Topics\n",
    "\n",
    "The best way to evaluate our topics is to actually visualize them. Gensim has a package called pyLDAvis that works with gensim's LDA model to build topic visualizations.\n",
    "\n",
    "Above, we can see a representation of our three topics on the left as bubbles. The size of the bubbles corresponds with the significance of the topic and the separation between the bubbles tell us how sparse they are i.e. how different they are from each other. \n",
    "\n",
    "pyLDAvis is also an interactive visual. If we hover over each bubble, the right side of the visual tells us, in order, which terms are the most frequent for each topic in red. In blue, it shows us the overall frequency of the terms in the documents.\n",
    "\n",
    "This visualization produced is actually quite encouraging because our topics are all sparse and significant, and we can clearly see which words are most important to which topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Corpus with Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33333333399843246\n"
     ]
    }
   ],
   "source": [
    "# Assigns the topics to the documents in corpus\n",
    "lda_corpus = lda[corpus]\n",
    "\n",
    "# Find the threshold, let's set the threshold to be 1/#clusters,\n",
    "# To prove that the threshold is sane, we average the sum of all probabilities:\n",
    "scores = list(chain(*[[score for topic_id,score in topic] \\\n",
    "                      for topic in [doc for doc in lda_corpus]]))\n",
    "threshold = sum(scores)/len(scores)\n",
    "print (threshold)\n",
    "\n",
    "reliability = [j for i,j in zip(lda_corpus,data) if i[0][1] > threshold]\n",
    "function = [j for i,j in zip(lda_corpus,data) if i[1][1] > threshold]\n",
    "design = [j for i,j in zip(lda_corpus,data) if i[2][1] > threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe of document groups for topics\n",
    "topics_df = pd.DataFrame(reliability, columns=['reliability'])\n",
    "topics_df['function'] = pd.DataFrame(function)\n",
    "topics_df['design'] = pd.DataFrame(design)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_df = json_data\n",
    "\n",
    "# Assign labels as binary topics\n",
    "labelled_df['reliability'] = \"\"\n",
    "labelled_df['function'] = \"\"\n",
    "labelled_df['design'] = \"\"\n",
    "\n",
    "labelled_df['reliability'] = np.where(labelled_df['text'].isin(reliability), 'reliability', None)\n",
    "labelled_df['function'] = np.where(labelled_df['text'].isin(function), 'function', None)\n",
    "labelled_df['design'] = np.where(labelled_df['text'].isin(design), 'design', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>reliability</th>\n",
       "      <th>function</th>\n",
       "      <th>design</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Julian Chokkattu</td>\n",
       "      <td>Google’s annual hardware launch event will tak...</td>\n",
       "      <td>Google will announce hardware on October 9, ne...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>design</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Christian de Looper</td>\n",
       "      <td>Google finally unveiled the new Google Pixel 3...</td>\n",
       "      <td>Here’s how to buy the new Google Pixel 3 and G...</td>\n",
       "      <td>reliability</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Simon Hill</td>\n",
       "      <td>If you plan to buy one of Google’s Pixel 3 sma...</td>\n",
       "      <td>The best Pixel 3 cases and covers</td>\n",
       "      <td>None</td>\n",
       "      <td>function</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Simon Hill</td>\n",
       "      <td>As the developer of Android, Google turns out ...</td>\n",
       "      <td>Google Pixel 3 vs. Pixel 2 vs. Pixel: Picking ...</td>\n",
       "      <td>reliability</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Simon Hill</td>\n",
       "      <td>There are plenty of contenders in the Android ...</td>\n",
       "      <td>Google Pixel 3 vs. Samsung Galaxy S9: Which sm...</td>\n",
       "      <td>reliability</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                author                                               text  \\\n",
       "0     Julian Chokkattu  Google’s annual hardware launch event will tak...   \n",
       "1  Christian de Looper  Google finally unveiled the new Google Pixel 3...   \n",
       "2           Simon Hill  If you plan to buy one of Google’s Pixel 3 sma...   \n",
       "3           Simon Hill  As the developer of Android, Google turns out ...   \n",
       "4           Simon Hill  There are plenty of contenders in the Android ...   \n",
       "\n",
       "                                               title  reliability  function  \\\n",
       "0  Google will announce hardware on October 9, ne...         None      None   \n",
       "1  Here’s how to buy the new Google Pixel 3 and G...  reliability      None   \n",
       "2                  The best Pixel 3 cases and covers         None  function   \n",
       "3  Google Pixel 3 vs. Pixel 2 vs. Pixel: Picking ...  reliability      None   \n",
       "4  Google Pixel 3 vs. Samsung Galaxy S9: Which sm...  reliability      None   \n",
       "\n",
       "   design  \n",
       "0  design  \n",
       "1    None  \n",
       "2    None  \n",
       "3    None  \n",
       "4    None  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine labels into column\n",
    "labelled_df['labelled'] = labelled_df[['reliability', 'function', 'design']].values.tolist()\n",
    "labelled_df['labelled'] = labelled_df['labelled'].apply(lambda x: list(filter(lambda a: a != None, x)))\n",
    "labelled_df = labelled_df.drop(['reliability', 'function', 'design'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>labelled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Julian Chokkattu</td>\n",
       "      <td>Google’s annual hardware launch event will tak...</td>\n",
       "      <td>Google will announce hardware on October 9, ne...</td>\n",
       "      <td>[design]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Christian de Looper</td>\n",
       "      <td>Google finally unveiled the new Google Pixel 3...</td>\n",
       "      <td>Here’s how to buy the new Google Pixel 3 and G...</td>\n",
       "      <td>[reliability]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Simon Hill</td>\n",
       "      <td>If you plan to buy one of Google’s Pixel 3 sma...</td>\n",
       "      <td>The best Pixel 3 cases and covers</td>\n",
       "      <td>[function]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Simon Hill</td>\n",
       "      <td>As the developer of Android, Google turns out ...</td>\n",
       "      <td>Google Pixel 3 vs. Pixel 2 vs. Pixel: Picking ...</td>\n",
       "      <td>[reliability]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Simon Hill</td>\n",
       "      <td>There are plenty of contenders in the Android ...</td>\n",
       "      <td>Google Pixel 3 vs. Samsung Galaxy S9: Which sm...</td>\n",
       "      <td>[reliability]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                author                                               text  \\\n",
       "0     Julian Chokkattu  Google’s annual hardware launch event will tak...   \n",
       "1  Christian de Looper  Google finally unveiled the new Google Pixel 3...   \n",
       "2           Simon Hill  If you plan to buy one of Google’s Pixel 3 sma...   \n",
       "3           Simon Hill  As the developer of Android, Google turns out ...   \n",
       "4           Simon Hill  There are plenty of contenders in the Android ...   \n",
       "\n",
       "                                               title       labelled  \n",
       "0  Google will announce hardware on October 9, ne...       [design]  \n",
       "1  Here’s how to buy the new Google Pixel 3 and G...  [reliability]  \n",
       "2                  The best Pixel 3 cases and covers     [function]  \n",
       "3  Google Pixel 3 vs. Pixel 2 vs. Pixel: Picking ...  [reliability]  \n",
       "4  Google Pixel 3 vs. Samsung Galaxy S9: Which sm...  [reliability]  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Mutli-Label Classifier Models\n",
    "\n",
    "We need to train a Mutli-Label Classifier so that we can use this model to assign aspect sentiments to topics later on. We're going to compare the performance of ML-Naive Bayes and ML-Support Vector Machines and then decide on which one we'll use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the multi-labels into arrays\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(labelled_df.labelled)\n",
    "X = labelled_df.text\n",
    "\n",
    "# Split data into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "\n",
    "# save the the fitted binarizer labels\n",
    "# This is important: it contains the how the multi-label was binarized, so you need to\n",
    "# load this in the next folder in order to undo the transformation for the correct labels.\n",
    "filename = 'mlb.pkl'\n",
    "pickle.dump(mlb, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8009259259259259"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LabelPowerset allows for multi-label classification\n",
    "# Build a pipeline for multinomial naive bayes classification\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words = \"english\",ngram_range=(1, 1))),\n",
    "                     ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "                     ('clf', LabelPowerset(MultinomialNB(alpha=1e-1))),])\n",
    "\n",
    "text_clf = text_clf.fit(X_train, y_train)\n",
    "predicted = text_clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "np.mean(predicted == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8564814814814815"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test if SVM performs better\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer()),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf-svm', LabelPowerset(\n",
    "                             SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                           alpha=1e-3, max_iter=6, random_state=42)))])\n",
    "text_clf_svm = text_clf_svm.fit(X_train, y_train)\n",
    "predicted_svm = text_clf_svm.predict(X_test)\n",
    "\n",
    "#Calculate accuracy\n",
    "np.mean(predicted_svm == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.65      0.76        37\n",
      "           1       1.00      0.73      0.84        11\n",
      "           2       0.81      0.88      0.84        40\n",
      "\n",
      "   micro avg       0.87      0.76      0.81        88\n",
      "   macro avg       0.91      0.75      0.82        88\n",
      "weighted avg       0.88      0.76      0.81        88\n",
      " samples avg       0.88      0.81      0.82        88\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# View accuracy scores on classifying each author (precission, recall, f1-score and support)\n",
    "print(metrics.classification_report(y_test, predicted_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Mutli-Label Classifiers\n",
    "\n",
    "When comparing the two models, SVM performs significantly better than the Naive Bayes with an 85.6% accuracy. The average precision, recall and f1-scores are also consistent and very promising, ranging from 86% to 90%. The only concerning number are the low recall scores that range from 65% to 88%. I think we can improve on these results by tuning the hyperparameters more specifically. But having more data to train on would also help\n",
    "\n",
    "So, for our Aspect-Based Opinion Mining notebook, we're going to use the SVM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train naive bayes on full dataset and save model\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer(stop_words = \"english\",ngram_range=(1, 1))),\n",
    "                     ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "                     ('clf', LabelPowerset(MultinomialNB(alpha=1e-1))),])\n",
    "text_clf_svm = text_clf.fit(X, y)\n",
    "\n",
    "# save the model to disk\n",
    "filename = 'svm_model.pkl'\n",
    "pickle.dump(text_clf_svm, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continue to Second Notebook: 02 Opinion Mining - Aspect Based Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "1. \"Apple iPhone sales 2018.\" Statista. Statista. 19 Feb. 2019 <https://www.statista.com/statistics/263401/global-apple-iphone-sales-since-3rd-quarter-2007/>.\n",
    "\n",
    "2. Bansal, Shivam, and Natural Language Processing and Machine Learning. \"Beginners Guide to Topic Modeling in Python.\" Analytics Vidhya. 11 Jan. 2019. 19 Feb. 2019 <https://www.analyticsvidhya.com/blog/2016/08/beginners-guide-to-topic-modeling-in-python/>.\n",
    "\n",
    "3. Li, Susan. \"Topic Modeling and Latent Dirichlet Allocation (LDA) in Python.\" Towards Data Science. 31 May 2018. Towards Data Science. 19 Feb. 2019 <https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24>.\n",
    "\n",
    "4. Li, Susan. \"Topic Modelling in Python with NLTK and Gensim – Towards Data Science.\" Towards Data Science. 30 Mar. 2018. Towards Data Science. 19 Feb. 2019 <https://towardsdatascience.com/topic-modelling-in-python-with-nltk-and-gensim-4ef03213cd21>.\n",
    "\n",
    "5. Min, Peter. \"Aspect-Based Opinion Mining (NLP with Python) – Peter Min – Medium.\" Medium.com. 06 June 2018. Medium. 19 Feb. 2019 <https://medium.com/@pmin91/aspect-based-opinion-mining-nlp-with-python-a53eb4752800>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
