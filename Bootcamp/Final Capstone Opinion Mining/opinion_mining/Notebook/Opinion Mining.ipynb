{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies and modules\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import string\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "from io import StringIO\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import glob\n",
    "import errno\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load each json file\n",
    "with open('iphonex_digtrends.json') as f:\n",
    "    iphonex_digtrends = json.load(f)\n",
    "\n",
    "with open('iphonex_gizmodo.json') as f:\n",
    "    iphonex_gizmodo = json.load(f)\n",
    "\n",
    "with open('iphonex_techradar.json') as f:\n",
    "    iphonex_techradar = json.load(f)\n",
    "\n",
    "with open('S9_digtrends.json') as f:\n",
    "    S9_digtrends = json.load(f)\n",
    "\n",
    "with open('S9_gizmodo.json') as f:\n",
    "    S9_gizmodo = json.load(f)\n",
    "\n",
    "with open('S9_techradar.json') as f:\n",
    "    S9_techradar = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for standard text cleaning.\n",
    "def text_cleaner(text):\n",
    "    # Visual inspection identifies a form of punctuation spaCy does not\n",
    "    # recognize: the double dash '--'.  Better get rid of it now!\n",
    "\n",
    "    text = str(text).replace(\"\\n\", \"\")\n",
    "    text = str(text).replace(\"\\t\", \"\")\n",
    "    text = str(text).replace(\"\\\\n\", \"\")\n",
    "    text = str(text).replace(\"\\\\t\", \"\")\n",
    "    text = str(text).replace(\"\\\\\", \"\")\n",
    "    text = str(text).replace(\"xa0\", \" \")\n",
    "    text = str(text).replace(\"\\'\", \"\")\n",
    "    text = re.sub(\"<p>\", \"\", str(text))\n",
    "    text = re.sub(\"</p>\", \"\", str(text))\n",
    "    text = re.sub(\"</a>\", \"\", str(text))\n",
    "    text = re.sub('<[^>]+>', \"\", str(text))\n",
    "    text = str(text).replace(\"\\\\u2019\", \"\")\n",
    "    text = str(text).replace(\"\\\\u2013\", \"\")\n",
    "    text = str(text).replace(\"\\\\u2018\", \"\")\n",
    "    text = str(text).replace(\"\\\\u00a0\", \"\")\n",
    "    text = str(text).replace(\"\\\\u00a3\", \"\")\n",
    "    text = str(text).replace(\"\\u2014\", \"\")\n",
    "    text = str(text).replace(\"\\u201d\", \"\")\n",
    "    text = str(text).replace(\"\\u201c\", \"\")\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate each JSON file into a data frame\n",
    "\n",
    "iphonex_digtrends = pd.DataFrame.from_dict(iphonex_digtrends, orient='columns')\n",
    "iphonex_gizmodo = pd.DataFrame.from_dict(iphonex_gizmodo, orient='columns')\n",
    "iphonex_techradar = pd.DataFrame.from_dict(iphonex_techradar, orient='columns')\n",
    "S9_digtrends = pd.DataFrame.from_dict(S9_digtrends, orient='columns')\n",
    "S9_gizmodo = pd.DataFrame.from_dict(S9_gizmodo, orient='columns')\n",
    "S9_techradar = pd.DataFrame.from_dict(S9_techradar, orient='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to clean text\n",
    "def clean_text(df):\n",
    "    # Convert lists to strings and remove brackets\n",
    "    df['text'] = df['text'].astype(str)\n",
    "    df['author'] = df['author'].astype(str)\n",
    "\n",
    "    df['text'] = df['text'].map(lambda x: x.strip('[]'))\n",
    "    df['author'] = df['author'].map(lambda x: x.strip('[]'))\n",
    "\n",
    "    # Clean text\n",
    "    df['text'] = df['text'].apply(lambda x: text_cleaner(x))\n",
    "    df['title'] = df['title'].apply(lambda x: text_cleaner(x))\n",
    "    df['author'] = df['author'].apply(lambda x: text_cleaner(x))\n",
    "\n",
    "    \n",
    "# Put dataframes into a list to iterate through\n",
    "dataframes = [iphonex_digtrends, iphonex_gizmodo, iphonex_techradar, S9_digtrends, S9_gizmodo, S9_techradar]\n",
    "\n",
    "# Clean each Data Frame\n",
    "for dataframe in dataframes:\n",
    "    clean_text(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label all the rows in the dataframe for the phone that the article is talking about\n",
    "\n",
    "iphones = [iphonex_digtrends, iphonex_gizmodo, iphonex_techradar]\n",
    "s9s = [S9_digtrends, S9_gizmodo, S9_techradar]\n",
    "\n",
    "for dataframe in iphones:\n",
    "    dataframe['phone'] = 'IPhone X'\n",
    "    \n",
    "for dataframe in s9s:\n",
    "    dataframe['phone'] = 'Samsung Galaxy S9'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat all the dataframes into one dataframe\n",
    "all_frames = [iphonex_digtrends, iphonex_gizmodo, iphonex_techradar, S9_digtrends, S9_gizmodo, S9_techradar]\n",
    "df = pd.concat(all_frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>phone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Eric Brackett</td>\n",
       "      <td>The iPhone X launched to stellar reviews and e...</td>\n",
       "      <td>Shrinking demand forces Apple to slow down iPh...</td>\n",
       "      <td>IPhone X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lucas Coll</td>\n",
       "      <td>When it comes to high-quality devices, like th...</td>\n",
       "      <td>Looking to upgrade? These are the best iPhone ...</td>\n",
       "      <td>IPhone X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Simon Hill</td>\n",
       "      <td>The iPhone X is completely different from any ...</td>\n",
       "      <td>The most common iPhone X problems, and how to ...</td>\n",
       "      <td>IPhone X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trevor Mogg</td>\n",
       "      <td>If you’re in the market for an iPhone X, and p...</td>\n",
       "      <td>This $4,600 solar charger comes with an iPhone...</td>\n",
       "      <td>IPhone X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mark Jansen</td>\n",
       "      <td>, The initial estimates, set during the Novemb...</td>\n",
       "      <td>Apple will halve iPhone X production after lim...</td>\n",
       "      <td>IPhone X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          author                                               text  \\\n",
       "0  Eric Brackett  The iPhone X launched to stellar reviews and e...   \n",
       "1     Lucas Coll  When it comes to high-quality devices, like th...   \n",
       "2     Simon Hill  The iPhone X is completely different from any ...   \n",
       "3    Trevor Mogg  If you’re in the market for an iPhone X, and p...   \n",
       "4    Mark Jansen  , The initial estimates, set during the Novemb...   \n",
       "\n",
       "                                               title     phone  \n",
       "0  Shrinking demand forces Apple to slow down iPh...  IPhone X  \n",
       "1  Looking to upgrade? These are the best iPhone ...  IPhone X  \n",
       "2  The most common iPhone X problems, and how to ...  IPhone X  \n",
       "3  This $4,600 solar charger comes with an iPhone...  IPhone X  \n",
       "4  Apple will halve iPhone X production after lim...  IPhone X  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Process Data for NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tokenize text\n",
    "# df['text'] = df.apply(lambda row: nltk.word_tokenize(row['text']), axis=1)\n",
    "# df['title'] = df.apply(lambda row: nltk.word_tokenize(row['title']), axis=1)\n",
    "\n",
    "# # Remove Stopwords, or keep it, might be important for aspect based semantics\n",
    "# stop = stopwords.words('english')\n",
    "# df['text'] = df['text'].apply(lambda x: [item for item in x if item not in stop])\n",
    "# df['title'] = df['title'].apply(lambda x: [item for item in x if item not in stop])\n",
    "\n",
    "# # Lowercase everything\n",
    "# df['text'] = df['text'].astype(str)\n",
    "# df['text'] = df['text'].apply(lambda x: x.lower())\n",
    "\n",
    "# df['title'] = df['title'].astype(str)\n",
    "# df['title'] = df['title'].apply(lambda x: x.lower())\n",
    "\n",
    "# # remove all punctuations\n",
    "# df['text'] = df['text'].apply(lambda x: ''.join(c for c in x if c not in punctuation))\n",
    "# df['title'] = df['title'].apply(lambda x: ''.join(c for c in x if c not in punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n",
    "\n",
    "spacy.load('en')\n",
    "parser = English()\n",
    "\n",
    "# Function to tokenize text\n",
    "def tokenize(text):\n",
    "    lda_tokens = []\n",
    "    tokens  = parser(text)\n",
    "    for token in tokens:\n",
    "        if token.orth_.isspace():\n",
    "            continue\n",
    "        elif token.like_url:\n",
    "            lda_tokens.append('URL')\n",
    "        elif token.orth_.startswith('@'):\n",
    "            lda_tokens.append('SCREEN_NAME')\n",
    "        else:\n",
    "            lda_tokens.append(token.lower_)\n",
    "    return lda_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ayankarim/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download wordnet to find meaning of words, synonyms and antonyms\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ayankarim/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "# Function to lemmatize and more words to their root\n",
    "def get_lemma(word):\n",
    "    lemma = wn.morphy(word)\n",
    "    if lemma is None:\n",
    "        return word\n",
    "    else:\n",
    "        return lemma\n",
    "    \n",
    "# Compile set of stopwords\n",
    "nltk.download('stopwords')\n",
    "en_stop = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "def prepare_text_for_lda(text):\n",
    "    tokens = tokenize(text)\n",
    "    tokens = [token for token in tokens if len(token) > 4]\n",
    "    tokens = [token for token in tokens if token not in en_stop]\n",
    "    tokens = [get_lemma(token) for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = []\n",
    "\n",
    "# Prepare training set for LDA\n",
    "tokens = df['text'].apply(lambda x: prepare_text_for_lda(x))\n",
    "\n",
    "# Prepare Dataframe for later\n",
    "df['text'] = df['text'].apply(lambda x: prepare_text_for_lda(x))\n",
    "\n",
    "# Append tokenized text to list of tokenized data\n",
    "null = tokens.apply(lambda x: text_data.append(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Clean Title Column\n",
    "\n",
    "# # Tokenize text\n",
    "# df['title'] = df.apply(lambda row: nltk.word_tokenize(row['title']), axis=1)\n",
    "\n",
    "# # Remove Stopwords, or keep it, might be important for aspect based semantics\n",
    "# stop = stopwords.words('english')\n",
    "# df['title'] = df['title'].apply(lambda x: [item for item in x if item not in stop])\n",
    "\n",
    "# # Lowercase everything\n",
    "# df['title'] = df['title'].astype(str)\n",
    "# df['title'] = df['title'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>phone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Eric Brackett</td>\n",
       "      <td>[iphone, launch, stellar, review, equally, str...</td>\n",
       "      <td>Shrinking demand forces Apple to slow down iPh...</td>\n",
       "      <td>IPhone X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lucas Coll</td>\n",
       "      <td>[come, quality, devices, macbook, homepod, app...</td>\n",
       "      <td>Looking to upgrade? These are the best iPhone ...</td>\n",
       "      <td>IPhone X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Simon Hill</td>\n",
       "      <td>[iphone, completely, different, predecessor, f...</td>\n",
       "      <td>The most common iPhone X problems, and how to ...</td>\n",
       "      <td>IPhone X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trevor Mogg</td>\n",
       "      <td>[market, iphone, pricey, battery, pack, happen...</td>\n",
       "      <td>This $4,600 solar charger comes with an iPhone...</td>\n",
       "      <td>IPhone X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mark Jansen</td>\n",
       "      <td>[initial, estimate, november, launch, window, ...</td>\n",
       "      <td>Apple will halve iPhone X production after lim...</td>\n",
       "      <td>IPhone X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          author                                               text  \\\n",
       "0  Eric Brackett  [iphone, launch, stellar, review, equally, str...   \n",
       "1     Lucas Coll  [come, quality, devices, macbook, homepod, app...   \n",
       "2     Simon Hill  [iphone, completely, different, predecessor, f...   \n",
       "3    Trevor Mogg  [market, iphone, pricey, battery, pack, happen...   \n",
       "4    Mark Jansen  [initial, estimate, november, launch, window, ...   \n",
       "\n",
       "                                               title     phone  \n",
       "0  Shrinking demand forces Apple to slow down iPh...  IPhone X  \n",
       "1  Looking to upgrade? These are the best iPhone ...  IPhone X  \n",
       "2  The most common iPhone X problems, and how to ...  IPhone X  \n",
       "3  This $4,600 solar charger comes with an iPhone...  IPhone X  \n",
       "4  Apple will halve iPhone X production after lim...  IPhone X  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RESEARCH HOW TO DO ABSA WITHOUT TOPICS\n",
    "\n",
    "### Identify opinion words by cross referencing the words with the opinion lexicon for negative and positive words\n",
    "\n",
    "### Research Spacy Dependency Parser to identify other words dependant or linked to opinion words\n",
    "    ### Allows you to extract the aspect related to the sentiment\n",
    "    \n",
    "### Define rules to set correct sentiment scores to opinion words\n",
    "\n",
    "### Assign sentiment scores to each aspect term that the opinion words are referring to\n",
    "\n",
    "### MAY NEED TO SCRAPE TEST DATA. PERHAPS TWO DIFFERENT PHONES!!!!! TEST MODEL ON TEST DATA TO SEE HOW IT ANALYSES SENTIMENT AND OUTPUTS OUR RESULT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
