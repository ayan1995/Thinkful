{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now have a fairly substantial starting toolbox of supervised learning methods that you can use to tackle a host of exciting problems. To make sure all of these ideas are organized in your mind, please go through the list of problems below. For each, identify which supervised learning method(s) would be best for addressing that particular problem. Explain your reasoning and discuss your answers with your mentor.\n",
    "\n",
    "1. Predict the running times of prospective Olympic sprinters using data from the last 20 Olympics.\n",
    "2. You have more features (columns) than rows in your dataset.\n",
    "3. Identify the most important characteristic predicting likelihood of being jailed before age 20.\n",
    "4. Implement a filter to “highlight” emails that might be important to the recipient\n",
    "5. You have 1000+ features.\n",
    "6. Predict whether someone who adds items to their cart on a website will purchase the items.\n",
    "7. Your dataset dimensions are 982400 x 500\n",
    "8. Identify faces in an image.\n",
    "9. Predict which of three flavors of ice cream will be most popular with boys vs girls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Predict the running times of prospective Olympic sprinters using data from the last 20 Olympics.\n",
    "\n",
    "1. The first model I would use is a multivariable regression model. Our historic data would include fairly simple features that can be represented in a linear function and reveal plenty of insights in sprint trends over time as well as correlation of running times between different events(100m vs 200m). Our feature engineering would be kept simple to dimension reduction and other simple manipulations due to the large amount of colinearity. Because the features are all similar (sprint times for different event and olympians perhaps), a simple regression model like linear regression would be more that sufficient.\n",
    "\n",
    "2. The second model I would use is a KNN regression model. As said before, since sprint times are pretty simplistic features that correlate when the speed of olympians are similar. KNN can use the sprint data to group similar olympians together and predict accurate sprint times of prospective olympians, based on the historic olympians that ran at similar speeds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. You have more features (columns) than rows in your dataset.\n",
    "\n",
    "1. Here, I would use a ridge or lass regression so that I can regularize or minimize the effects of a large amount of features by penalizing them as their coefficients grow to incredibly large values. This will help reduce the overfitting that would occur when there a large amount of features.\n",
    "\n",
    "2. Random Forest could also be applied here, especially for classification. This is because the large number of features can used as many different combination of nodes with respective rules in the decision trees and thus will give us a more accurate prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Identify the most important characteristic predicting likelihood of being jailed before age 20.\n",
    "\n",
    "1. Here I would use a multivariable linear regression model and then I would rate the predictors based on their coefficients as well as their significance through t-tests. This way I can identify which predictors had the most effect in predicting whether someone would be jailed before 20 and therefore it would be the most important characteristic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Implement a filter to “highlight” emails that might be important to the recipient\n",
    "\n",
    "1. I would use Naive Bayes classifier to to identify which emails are important to the recipient and then filter them. This is a fairly simple sentiment analysis so a simple model like Naive Bayes would be appropriate. We can attain a high degree of accuracy using TF-IDF vectorizer and it would be simple to impliment and optimize.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. You have 1000+ features.\n",
    "\n",
    "1. I would use a lasso regression to penalize features that are large. This would reduce the coefficients of many features to 0 and improve the efficiency of our model by removing many unnecessary features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Predict whether someone who adds items to their cart on a website will purchase the items.\n",
    "\n",
    "1. A Logistic Regression can classify the probability people purchasing items with good accuracy and is the simplest model to impliment when predicting if someone will purchase items or not.\n",
    "\n",
    "2. A Random Forest, or even a decision tree would be a good model to predict whether or not someone will buy the item. This implies that we have data on other variables such as whether they've purchased items before, click rates, total purchases etc. But rules set up on nodes from different predictors can help us indicate whether they'll buy the items.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Your dataset dimensions are 982400 x 500\n",
    "\n",
    "1. I would use a KNN model. It would make accurate predictions because it would have plenty of data points to use as nearest neighbors when voting on the probability in classifications and/or averaging on regression. Furthermore, it's relatively efficient compared to other models that would take extremely long to process, especially since we can define the number of K-nearest-neighbors to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Identify faces in an image.\n",
    "\n",
    "1. I would use Gradient Boosting in this situation so that we can ensemble many simple models to gather as much accurate informatio on the image and pixels to classify the face."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Predict which of three flavors of ice cream will be most popular with boys vs girls.\n",
    "\n",
    "1. I would use KNN classifer to predict whether the gender of the customer is a boy based on the flavors that were bought and then I would inspect the values of the predictor coefficients and their significance to see which flavors were stronger predictors of it being a boy. That would be the most popular flavor for a boy. Then I would tune the model to predict if its a girl and repeat the same process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
